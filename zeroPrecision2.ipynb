{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading"
      ],
      "metadata": {
        "id": "BIetMu2KQdYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr-PmHWLZ_QO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.read_excel('/content/gdrive/MyDrive/Y_train.xlsx')\n",
        "x_train = dd.read_csv('/content/gdrive/MyDrive/DS_train(2020-06--2022-06-01).csv', sep='\\\\t', blocksize=64000000)\n",
        "x_train = x_train.iloc[:,[0,1,2,3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DbofXYj-HNc",
        "outputId": "a49a3922-fc33-4f30-818a-85f7c8825d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_with_only_instock = x_train.dropna()\n",
        "x_train2 = x_train_with_only_instock[x_train_with_only_instock['DateObserve'] > '2022-03-28']\n",
        "pd_train2 = x_train2.compute()"
      ],
      "metadata": {
        "id": "cHEjA-E7-dk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obsevations1 = pd_train2.groupby(by='WebPriceId').DateObserve.nunique()"
      ],
      "metadata": {
        "id": "3l2k7ZO-zSVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obsevations = obsevations1[(obsevations1 >= 4)]"
      ],
      "metadata": {
        "id": "SL_hddg08GCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goods_means = pd_train2[pd_train2['WebPriceId'].isin(obsevations.index)].groupby(by='WebPriceId').CurrentPrice.mean() #mean price for each one Id"
      ],
      "metadata": {
        "id": "spxo8wW83Ta3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "technique = goods_means[goods_means > goods_means.quantile(0.75)].index #0.75 quantile"
      ],
      "metadata": {
        "id": "DD5s-d5h4EjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "people_goods = goods_means[goods_means <= goods_means.quantile(0.25)].index #0.25 quantile"
      ],
      "metadata": {
        "id": "9nr-39Z63bye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other_goods = goods_means[(goods_means > goods_means.quantile(0.25)) & (goods_means <= goods_means.quantile(0.75))].index #from 0.25 to 0.75 quantile"
      ],
      "metadata": {
        "id": "17oF6Sas3qYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = np.concatenate([np.concatenate([np.array(people_goods), np.array(technique)]), np.array(other_goods)])"
      ],
      "metadata": {
        "id": "u77gvEl3ZErg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = x_train_with_only_instock[x_train_with_only_instock['WebPriceId'].isin(indexes)]\n",
        "\n",
        "dataset = dataset.drop('StockStatus', axis=1) \n",
        "\n",
        "dataset = dataset.compute()\n",
        "\n",
        "dataset['DateObserve'] = pd.to_datetime(dataset['DateObserve'], yearfirst=True).dt.to_period('h')\n",
        "  \n",
        "dataset.to_csv('Train.csv', index=False)"
      ],
      "metadata": {
        "id": "MIZCo_LzXWwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "oGbOeh9Dxhoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('Train.csv')\n",
        "train_data['DateObserve'] = pd.to_datetime(train_data['DateObserve'], yearfirst=True).dt.to_period('D')\n",
        "\n",
        "people_ids = people_goods\n",
        "technique_ids = technique\n",
        "other_ids = other_goods\n",
        "\n",
        "people = train_data[train_data['WebPriceId'].isin(people_ids)].drop('WebPriceId', axis=1)\n",
        "technique = train_data[train_data['WebPriceId'].isin(technique_ids)].drop('WebPriceId', axis=1)\n",
        "other = train_data[train_data['WebPriceId'].isin(other_ids)].drop('WebPriceId', axis=1)\n",
        "\n",
        "people = people.groupby(by='DateObserve').CurrentPrice.mean().to_frame().reset_index()\n",
        "technique = technique.groupby(by='DateObserve').CurrentPrice.mean().to_frame().reset_index()\n",
        "other = other.groupby(by='DateObserve').CurrentPrice.mean().to_frame().reset_index()\n",
        "\n",
        "people = people.rename(columns={'CurrentPrice': 'PeoplePrice'})\n",
        "technique = technique.rename(columns={'CurrentPrice': 'TechniquePrice'})\n",
        "other = other.rename(columns={'CurrentPrice': 'OtherPrice'})"
      ],
      "metadata": {
        "id": "lWoR1IIust77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_set = train_data.groupby(by='DateObserve').CurrentPrice.mean().to_frame().reset_index()\n",
        "global_set = pd.merge(global_set, people, on=['DateObserve'], how='left')\n",
        "global_set = pd.merge(global_set, technique, on=['DateObserve'], how='left')\n",
        "global_set = pd.merge(global_set, other, on=['DateObserve'], how='left')\n",
        "\n",
        "global_set = global_set.fillna({'PeoplePrice': global_set.PeoplePrice.median(), \n",
        "                   'TechniquePrice': global_set.TechniquePrice.median(),\n",
        "                   'OtherPrice': global_set.OtherPrice.median(),})"
      ],
      "metadata": {
        "id": "Qo6XEvqVvxvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_set = global_set.assign(Date = lambda x: pd.to_datetime(x['DateObserve'].dt.strftime('%Y-%m')))\n",
        "\n",
        "global_set.loc[global_set['Date'].isin(['2020-06-01']), 'Y'] = 0.28\n",
        "global_set.loc[global_set['Date'].isin(['2020-07-01']), 'Y'] = -0.065\n",
        "global_set.loc[global_set['Date'].isin(['2020-08-01']), 'Y'] = -0.005\n",
        "global_set.loc[global_set['Date'].isin(['2020-09-01']), 'Y'] = 0.315\n",
        "global_set.loc[global_set['Date'].isin(['2020-10-01']), 'Y'] = 0\n",
        "global_set.loc[global_set['Date'].isin(['2020-11-01']), 'Y'] = 0.375\n",
        "global_set.loc[global_set['Date'].isin(['2020-12-01']), 'Y'] = 0.35\n",
        "global_set.loc[global_set['Date'].isin(['2021-01-01']), 'Y'] = 0.38\n",
        "global_set.loc[global_set['Date'].isin(['2021-02-01']), 'Y'] = 0.685\n",
        "global_set.loc[global_set['Date'].isin(['2021-03-01']), 'Y'] = 0.255\n",
        "global_set.loc[global_set['Date'].isin(['2021-04-01']), 'Y'] = 0.13\n",
        "global_set.loc[global_set['Date'].isin(['2021-05-01']), 'Y'] = 0.485\n",
        "global_set.loc[global_set['Date'].isin(['2021-06-01']), 'Y'] = 0.25\n",
        "global_set.loc[global_set['Date'].isin(['2021-07-01']), 'Y'] = -0.135\n",
        "global_set.loc[global_set['Date'].isin(['2021-08-01']), 'Y'] = 0.35\n",
        "global_set.loc[global_set['Date'].isin(['2021-09-01']), 'Y'] = 0.345\n",
        "global_set.loc[global_set['Date'].isin(['2021-10-01']), 'Y'] = 0.675\n",
        "global_set.loc[global_set['Date'].isin(['2021-11-01']), 'Y'] = 0.74\n",
        "global_set.loc[global_set['Date'].isin(['2021-12-01']), 'Y'] = 1.255\n",
        "global_set.loc[global_set['Date'].isin(['2022-01-01']), 'Y'] = 0.355\n",
        "global_set.loc[global_set['Date'].isin(['2022-02-01']), 'Y'] = 1.355\n",
        "global_set.loc[global_set['Date'].isin(['2022-03-01']), 'Y'] = 3.555\n",
        "global_set.loc[global_set['Date'].isin(['2022-04-01']), 'Y'] = 1.89\n",
        "global_set.loc[global_set['Date'].isin(['2022-05-01']), 'Y'] = 1.56\n",
        "\n",
        "global_set = global_set.drop('Date', axis=1)"
      ],
      "metadata": {
        "id": "eDUNzGxFFfZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_set = global_set.set_index('DateObserve')\n",
        "\n",
        "global_set['Ind'] = np.arange(global_set.shape[0])\n",
        "for i in range(1, 5):\n",
        "  global_set[f'ShiftCP{i}'] = global_set['CurrentPrice'].shift(i)\n",
        "  global_set[f'ShiftPP{i}'] = global_set['PeoplePrice'].shift(i)\n",
        "  global_set[f'ShiftTP{i}'] = global_set['TechniquePrice'].shift(i)\n",
        "  global_set[f'ShiftOP{i}'] = global_set['OtherPrice'].shift(i)\n",
        "global_set = global_set['2020-06-26':]\n",
        "\n",
        "for i in global_set.columns:\n",
        "  if i in ['CurrentPrice', 'PepoplePrice', 'OtherPrice', 'TechniquePrice']: \n",
        "    global_set[f'MA{i}'] = global_set[i].rolling(\n",
        "      window=30,       \n",
        "      center=True,      \n",
        "      min_periods=15).median()"
      ],
      "metadata": {
        "id": "qAbn8a6FgVjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "eRnuE8SjK0-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable \n",
        "\n",
        "X = global_set.drop('Y', axis=1)\n",
        "y = global_set.Y \n",
        "\n",
        "mm = MinMaxScaler()\n",
        "ss = StandardScaler()\n",
        "\n",
        "for_train = 300\n",
        "\n",
        "X_ss = ss.fit_transform(X)\n",
        "y_mm = mm.fit_transform(np.array(y).reshape(-1, 1)) \n",
        "\n",
        "X_train = X_ss[:for_train, :]\n",
        "X_test = X_ss[for_train:, :]\n",
        "\n",
        "y_train = y_mm[:for_train, :]\n",
        "y_test = y_mm[for_train:, :] \n",
        "\n",
        "\n",
        "X_train_tensors = Variable(torch.Tensor(X_train))\n",
        "X_test_tensors = Variable(torch.Tensor(X_test))\n",
        "\n",
        "y_train_tensors = Variable(torch.Tensor(y_train))\n",
        "y_test_tensors = Variable(torch.Tensor(y_test)) \n",
        "\n",
        "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
        "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) "
      ],
      "metadata": {
        "id": "c0gAkXnlK2Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM1(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "        super(LSTM1, self).__init__()\n",
        "        self.num_classes = num_classes \n",
        "        self.num_layers = num_layers \n",
        "        self.input_size = input_size \n",
        "        self.hidden_size = hidden_size \n",
        "        self.seq_length = seq_length \n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                          num_layers=num_layers, batch_first=True)\n",
        "        self.fc_1 =  nn.Linear(hidden_size, 128) \n",
        "        self.fc = nn.Linear(128, num_classes) \n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self,x):\n",
        "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
        "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
        "        hn = hn.view(-1, self.hidden_size)\n",
        "        out = self.relu(hn)\n",
        "        out = self.fc_1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "gXtyC03dLu8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 24 \n",
        "hidden_size = 10 \n",
        "num_layers = 1 \n",
        "\n",
        "num_classes = 1 \n",
        "\n",
        "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1])\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "
      ],
      "metadata": {
        "id": "Q8elN8qNLz6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  outputs = lstm1.forward(X_train_tensors_final)\n",
        "  optimizer.zero_grad()\n",
        "  loss = criterion(outputs, y_train_tensors)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "SxWYU6CIMJDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3319afb5-9894-43f4-ab5e-f14b1d659353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.16354\n",
            "Epoch: 100, loss: 0.00191\n",
            "Epoch: 200, loss: 0.00097\n",
            "Epoch: 300, loss: 0.00060\n",
            "Epoch: 400, loss: 0.00043\n",
            "Epoch: 500, loss: 0.00035\n",
            "Epoch: 600, loss: 0.00028\n",
            "Epoch: 700, loss: 0.00022\n",
            "Epoch: 800, loss: 0.00018\n",
            "Epoch: 900, loss: 0.00014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_ss = ss.transform(global_set.drop('Y', axis=1)) \n",
        "df_y_mm = mm.transform(np.array(global_set.Y).reshape(-1, 1))\n",
        "\n",
        "df_X_ss = Variable(torch.Tensor(df_X_ss)) \n",
        "df_y_mm = Variable(torch.Tensor(df_y_mm))\n",
        "\n",
        "df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], 1, df_X_ss.shape[1])) \n",
        "\n",
        "train_predict = lstm1(df_X_ss)\n",
        "df_X_ss = ss.transform(global_set.drop('Y', axis=1)) \n",
        "df_y_mm = mm.transform(np.array(global_set.Y).reshape(-1, 1)) \n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "data_predict = train_predict.data.numpy() \n",
        "data_predict = mm.inverse_transform(data_predict) \n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(data_predict, global_set.Y)"
      ],
      "metadata": {
        "id": "9J9nxsDEMUD-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}